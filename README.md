# List of Papers

## RL

Evolution-Guided Policy Gradient in Reinforcement Learning
[[paper](https://proceedings.neurips.cc/paper/2018/file/85fc37b18c57097425b52fc7afbb6969-Paper.pdf)] 
[[github](https://github.com/ShawK91/Evolutionary-Reinforcement-Learning)]

World Models
[[paper](https://arxiv.org/pdf/1803.10122.pdf)]
[[page](https://worldmodels.github.io)]

SuperTrack: Motion Tracking for Physically Simulated Characters using Supervised Learning
[[paper](https://static-wordpress.akamaized.net/montreal.ubisoft.com/wp-content/uploads/2021/11/24183638/SuperTrack.pdf)]

DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills
[[paper](https://xbpeng.github.io/projects/DeepMimic/2018_TOG_DeepMimic.pdf)]
[[github](https://github.com/xbpeng/DeepMimic)] \
AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control
[[paper](https://xbpeng.github.io/projects/AMP/2021_TOG_AMP.pdf)]
[[github](https://github.com/xbpeng/DeepMimic)]

Learning Time-Critical Responses for Interactive Character Control
[[paper](https://mrl.snu.ac.kr/research/ProjectAgile/AGILE_2021_SIGGRAPH_author.pdf)]
[[github](https://github.com/snumrl/TimeCriticalResponse)]

## NLP

LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention
[[paper](https://arxiv.org/pdf/2010.01057.pdf)]

Cluster-Former: Clustering-based Sparse Transformer for Question Answering
[[paper](https://arxiv.org/pdf/2009.06097.pdf)]

Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering
[[paper](https://arxiv.org/pdf/1908.08167.pdf)]

Retrospective Reader for Machine Reading Comprehension
[[paper](https://arxiv.org/pdf/2001.09694.pdf)]

Sparse Sequence-to-Sequence Models
[[paper](https://arxiv.org/pdf/1905.05702.pdf)]

Sparse Text Generation
[[paper](https://arxiv.org/pdf/2004.02644.pdf)]

Implicit Maximum Likelihood Estimation
[[paper](https://arxiv.org/pdf/1809.09087.pdf)]

Natural Language Generation Using Reinforcement Learning with External Rewards
[[paper](https://arxiv.org/pdf/1911.11404.pdf)]

âˆž-former: Infinite Memory Transformer
[[paper](https://arxiv.org/pdf/2109.00301.pdf)]

## CV

Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss
[[paper](https://arxiv.org/pdf/1906.07413.pdf)]

## ETC
Gradients are Not All You Need
[[paper](https://arxiv.org/pdf/2111.05803.pdf)]
